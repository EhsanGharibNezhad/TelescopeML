{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7dd73-055c-4e31-9497-88a1200ff8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# ==================                                           ==================\n",
    "# ==================            BOHB Optimizer                 ==================\n",
    "# ==================                                           ==================\n",
    "# ===============================================================================  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class KerasWorker(Worker):\n",
    "    def __init__(self, \n",
    "                   X1_train, X1_val, X1_test, # Row-StandardScaled input spectra\n",
    "                   X2_train, X2_val, X2_test, # Col-StandardScaled Mix Max of all rows of input spetra\n",
    "                   y1_train, y1_val, y1_test, # Col-StandardScaled target feature 1\n",
    "                   y2_train, y2_val, y2_test, # Col-StandardScaled target feature 2\n",
    "                   y3_train, y3_val, y3_test, # Col-StandardScaled target feature 3\n",
    "                   y4_train, y4_val, y4_test, # Col-StandardScaled target feature 4                 \n",
    "                   *args, sleep_interval=0, **kwargs):\n",
    "\n",
    "            super().__init__(**kwargs)\n",
    "            self.sleep_interval = sleep_interval\n",
    "\n",
    "            # self.batch_size = 2**9\n",
    "\n",
    "\n",
    "            # train, val, test sets for input 1 (main 104 spectral features)\n",
    "            self.X1_train, self.X1_val, self.X1_test = X1_train, X1_val, X1_test\n",
    "\n",
    "            # train, val, test sets for input 2 (Min and Max 2 features)\n",
    "            self.X2_train, self.X2_val, self.X2_test = X2_train, X2_val, X2_test\n",
    "            \n",
    "            # train, val, test sets for target features            \n",
    "            self.y1_train, self.y1_val, self.y1_test = y1_train, y1_val, y1_test\n",
    "            self.y2_train, self.y2_val, self.y2_test = y2_train, y2_val, y2_test\n",
    "            self.y3_train, self.y3_val, self.y3_test = y3_train, y3_val, y3_test \n",
    "            self.y4_train, self.y4_val, self.y4_test = y4_train, y4_val, y4_test   \n",
    "\n",
    "\n",
    "            # self.input_shape = (104,1)\n",
    "            # print(np.shape(self.x_train), np.shape(self.y_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def compute(self, config, budget, working_directory, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Convolution Neural Networks to be optimized by BOHB package.\n",
    "        The input parameter \"config\" (dictionary) contains the sampled configurations passed by the bohb optimizer\n",
    "        \"\"\"\n",
    "        Conv__filters = config['Conv__filters']\n",
    "        Conv__kernel_size = config['Conv__kernel_size']\n",
    "        Conv__MaxPooling1D = config['Conv__MaxPooling1D']\n",
    "        Conv__NumberLayers = config['Conv__NumberLayers']\n",
    "        Conv__NumberBlocks = config['Conv__NumberBlocks']\n",
    "\n",
    "        FC__units = config['FC__units']\n",
    "        FC__units_temperature = config['FC__units_temperature']\n",
    "        FC__units_c_o_ratio = config['FC__units_c_o_ratio']\n",
    "        FC__units_gravity = config['FC__units_gravity']\n",
    "        FC__units_metallicity = config['FC__units_metallicity']\n",
    "        FC__NumberLayers = config['FC__NumberLayers']\n",
    "        \n",
    "        FC__dropout = config['FC__dropout']\n",
    "        \n",
    "        FC_out_dropout = config['FC_out_dropout']\n",
    "\n",
    "        FC_in_Conv__units = config['FC_in_Conv__units']\n",
    "        FC_in_Conv__dropout = config['FC_in_Conv__dropout']\n",
    "        \n",
    "\n",
    "        lr = config['lr']\n",
    "        # LeakyReLU_alpha = config['LeakyReLU_alpha']\n",
    "        # kernel_initializer_list = config['kernel_initializer_list']   \n",
    "        \n",
    "\n",
    "        ######### Shape of the inputs\n",
    "        input_1 = tf.keras.layers.Input(shape=(104, 1))\n",
    "        input_2 = tf.keras.layers.Input(shape=(2,))\n",
    "\n",
    "        \n",
    "        ######### Conv Blocks  ####################################\n",
    "        model = input_1\n",
    "        for b in range(0, Conv__NumberBlocks):\n",
    "            for l in range(0, Conv__NumberLayers):\n",
    "                model = Conv1D(filters = Conv__filters*(2)**b, \n",
    "                                  kernel_size = Conv__kernel_size, \n",
    "                                  strides = 1, \n",
    "                                  padding ='same', \n",
    "                                  activation = 'relu', \n",
    "                                  kernel_initializer = 'he_normal',\n",
    "                                  # kernel_regularizer=tf.keras.regularizers.l2(Conv__regularizer),\n",
    "                                  name = 'Conv__B'+str(b+1)+'_L'+str(l+1))(model) #(model if l != 0 and b != 0 else input_1)\n",
    "\n",
    "            model = MaxPooling1D(pool_size=(Conv__MaxPooling1D),\n",
    "                                name = 'MaxPooling1D__B'+str(b+1)+'_L'+str(l+1))(model)\n",
    "\n",
    "\n",
    "        ######### Flatten Layer   ####################################\n",
    "        model = Flatten()(model)\n",
    "\n",
    "\n",
    "        ######### FC Layer before the Concatenation   ################\n",
    "        model = Dense(FC_in_Conv__units, \n",
    "                                  activation = 'relu', \n",
    "                           kernel_initializer = 'he_normal',\n",
    "                           # kernel_regularizer=tf.keras.regularizers.l2(Conv__regularizer),\n",
    "                           name = 'FC_in_Conv__B'+str(1)+'_L'+str(1))(model)\n",
    "\n",
    "        model= Dropout(FC_in_Conv__dropout, #### Have different Drop out here!!! \n",
    "                        name = 'FC_in_Conv__Dropout__B'+str(b+1)+'_L'+str(l+1))(model)\n",
    "                \n",
    "                \n",
    "        ######### Concatenation Layer  ###############################\n",
    "        # Concatenate the outputs from the convolutional layers and dense layer\n",
    "        model = tf.keras.layers.concatenate([model, input_2], \n",
    "                                                           name='Concatenated_Layer')\n",
    "\n",
    "        ######### FC Block  ####################################\n",
    "        for b in range(1): # We need 1 Blocks\n",
    "            for l in range(FC__NumberLayers): # We can have multiple layers\n",
    "                model = Dense(FC__units, \n",
    "                                  activation = 'relu', \n",
    "                           kernel_initializer = 'he_normal',\n",
    "                           # kernel_regularizer=tf.keras.regularizers.l2(Conv__regularizer),\n",
    "                           name = 'FC__B'+str(b+1)+'_L'+str(l+1))(model)\n",
    "\n",
    "                model= Dropout(FC__dropout, \n",
    "                                       name = 'FC__Dropout__B'+str(b+1)+'_L'+str(l+1))(model)\n",
    "        \n",
    "        \n",
    "\n",
    "        ######### 3rd FC Block: gravity  ##############################\n",
    "    #         FC2 = FC__Drop\n",
    "\n",
    "        model2 = Dense(FC__units_gravity, \n",
    "                                  activation = 'relu', \n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        # kernel_regularizer=tf.keras.regularizers.l2(0.003/2),\n",
    "                        name = 'FC_block3_gravity')(model)\n",
    "        \n",
    "        model2= Dropout(FC_out_dropout, \n",
    "                               name = 'FC_block3_gravity__Dropout')(model2)\n",
    "        \n",
    "        out__gravity = Dense(1, \n",
    "                             activation = 'linear',\n",
    "                             kernel_initializer = 'he_normal',\n",
    "                             name = 'gravity')(model2)\n",
    "        \n",
    "\n",
    "        \n",
    "        ######### 3rd FC Block: c_o_ratio  ##############################\n",
    "        model2 = Dense(FC__units_c_o_ratio, \n",
    "                                  activation = 'relu', \n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        # kernel_regularizer=tf.keras.regularizers.l2(0.003/2),\n",
    "                        name = 'FC_block3_c_o_ratio')(model)\n",
    "        \n",
    "        model2= Dropout(FC_out_dropout, \n",
    "                               name = 'FC_block3_c_o_ratio__Dropout')(model2)\n",
    "\n",
    "\n",
    "        out__c_o_ratio = Dense(1, \n",
    "                               activation = 'linear',\n",
    "                               kernel_initializer = 'he_normal',\n",
    "                               # kernel_regularizer=tf.keras.regularizers.l2(0.003/2),\n",
    "                               name='c_o_ratio')(model2)\n",
    "\n",
    "        \n",
    "        ######### 3rd FC Block: metallicity  ##############################\n",
    "        model2 = Dense(FC__units_metallicity, \n",
    "                                  activation = 'relu', \n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        # kernel_regularizer=tf.keras.regularizers.l2(0.003/2),\n",
    "                        name = 'FC_block3_metallicity')(model)\n",
    "        \n",
    "        model2= Dropout(FC_out_dropout, \n",
    "                               name = 'FC_block3_metallicity__Dropout')(model2)\n",
    "\n",
    "        \n",
    "        out__metallicity = Dense(1, \n",
    "                                 activation = 'linear',\n",
    "                                 kernel_initializer = 'he_normal',\n",
    "                                 name='metallicity')(model2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ######### 3rd FC Block: temperature  ##############################\n",
    "        model2 = Dense(FC__units_temperature, \n",
    "                                  activation = 'relu', \n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        # kernel_regularizer=tf.keras.regularizers.l2(0.003/2),\n",
    "                        name = 'FC_block3_temperature')(model)\n",
    "        \n",
    "        model2= Dropout(FC_out_dropout, \n",
    "                               name = 'FC_block3_temperature__Dropout')(model2)\n",
    "        \n",
    "\n",
    "        out__temperature = Dense(1, \n",
    "                                 activation = 'linear',\n",
    "                                 name='temperature')(model2)\n",
    "\n",
    "\n",
    "        ######### OUTPUT   ################################################\n",
    "        # Create the model with two inputs and two outputs\n",
    "        model = tf.keras.Model(inputs=[input_1, input_2], \n",
    "                               outputs=[out__gravity, out__c_o_ratio, out__metallicity, out__temperature])\n",
    "\n",
    "        # Compile the model with an optimizer, loss function, and metrics\n",
    "        model.compile(loss='huber_loss', \n",
    "                      optimizer=keras.optimizers.Adam(lr = lr),  \n",
    "                      metrics=['mae'])\n",
    "        \n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "  \n",
    "        early_stop = EarlyStopping(monitor='loss', min_delta=4e-4, patience=50, mode='auto', \\\n",
    "                                       restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "        # YOU CAN ADD FUNCTION HERE TO ADD NOISE\n",
    "        history = model.fit(x = [self.X1_train, self.X2_train], \n",
    "                            y = [self.y1_train, self.y2_train, self.y3_train, self.y4_train],  #self.x_train, self.y_train,\n",
    "                          batch_size = 32, #config['batch_size'], # self.batch_size,\n",
    "                          validation_data=([self.X1_val, self.X2_val], [self.y1_val, self.y2_val, self.y3_val, self.y4_val]),\n",
    "                          #validation_split=0.2,\n",
    "                          epochs=int(budget),\n",
    "                          verbose=1,\n",
    "                          callbacks=[early_stop],\n",
    "                 )\n",
    "\n",
    "\n",
    "        train_score = model.evaluate(x = [self.X1_train, self.X2_train], \n",
    "                                     y = [self.y1_train, self.y2_train, self.y3_train, self.y4_train],\n",
    "                                     verbose=0)\n",
    "        val_score   = model.evaluate(x = [self.X1_val, self.X2_val], \n",
    "                                     y = [self.y1_val, self.y2_val, self.y3_val, self.y4_val],\n",
    "                                     verbose=0)\n",
    "        test_score  = model.evaluate(x = [self.X1_test, self.X2_test], \n",
    "                                     y = [self.y1_test, self.y2_test, self.y3_test, self.y4_test],\n",
    "                                     verbose=0)\n",
    "\n",
    "        #print(train_score, val_score, test_score)\n",
    "#             #import IPython; IPython.embed()\n",
    "        return ({\n",
    "                'loss': val_score[1], # remember: HpBandSter always minimizes!\n",
    "                'info': {       'test accuracy': test_score[1],\n",
    "                                        'train accuracy': train_score[1],\n",
    "                                        'validation accuracy': val_score[1],\n",
    "                                        'number of parameters': model.count_params(),\n",
    "                                },\n",
    "                'model' : model,\n",
    "                'history' : history,\n",
    "\n",
    "        })\n",
    "\n",
    "    @staticmethod\n",
    "    def get_configspace():\n",
    "        \"\"\"\n",
    "        It builds the configuration space with the needed hyperparameters.\n",
    "        It is easily possible to implement different types of hyperparameters.\n",
    "        Beside float-hyperparameters on a log scale, it is also able to handle categorical input parameter.\n",
    "        :return: ConfigurationsSpace-Object\n",
    "        \"\"\"\n",
    "        cs = CS.ConfigurationSpace()\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "        # Conv hyperparameters\n",
    "        Conv__filters = CategoricalHyperparameter(name='Conv__filters', choices=[4 , 8, 16, 32]) # NOTE: Apply the same categorical method for other unit and \n",
    "        Conv__kernel_size = UniformIntegerHyperparameter(name='Conv__kernel_size', lower=1, upper=8, default_value=1,  log=False) # ok\n",
    "        Conv__MaxPooling1D = UniformIntegerHyperparameter(name='Conv__MaxPooling1D', lower=1, upper=8, default_value=1, log=False) # ok\n",
    "        Conv__NumberLayers = UniformIntegerHyperparameter(name='Conv__NumberLayers', lower=1, upper=6, default_value=1,  log=False) # ok\n",
    "        Conv__NumberBlocks =  UniformIntegerHyperparameter(name='Conv__NumberBlocks', lower=1, upper=4, default_value=1,  log=False) # ok\n",
    "\n",
    "        # FC hyperparameters\n",
    "        FC__units = CategoricalHyperparameter(name='FC__units', choices=[8, 16, 32 , 64, 128, 256]) # NOTE: Apply the same categorical method for other unit and \n",
    "\n",
    "        FC__units_temperature = CategoricalHyperparameter(name='FC__units_temperature', choices=[8, 16, 32 , 64, 128, 256]) # the same\n",
    "        FC__units_metallicity = CategoricalHyperparameter(name='FC__units_metallicity', choices=[8, 16, 32 , 64, 128, 256]) # the same\n",
    "        FC__units_c_o_ratio = CategoricalHyperparameter(name='FC__units_c_o_ratio', choices=[8, 16, 32 , 64, 128, 256]) # the same\n",
    "        FC__units_gravity = CategoricalHyperparameter(name='FC__units_gravity', choices=[8, 16, 32 , 64, 128, 256]) # same\n",
    "\n",
    "        FC__NumberLayers = UniformIntegerHyperparameter(name='FC__NumberLayers', lower=1, upper=5, default_value=1,  log=False) \n",
    "        # FC__NumberBlocks = UniformIntegerHyperparameter(name='FC__NumberBlocks', lower=1, upper=5, default_value=1,  log=False) # DELETE - No blocks for FC\n",
    "        FC__dropout = UniformFloatHyperparameter(name='FC__dropout', lower=0.001, upper=0.4, default_value=0.02, log=True)\n",
    "        FC_out_dropout = UniformFloatHyperparameter(name='FC_out_dropout', lower=0.001, upper=0.4, default_value=0.02, log=True)\n",
    "        \n",
    "        FC_in_Conv__units = CategoricalHyperparameter(name='FC_in_Conv__units', choices=[8, 16, 32 , 64, 128, 256]) # same\n",
    "        #FC_in_Conv__NumberBlocks = UniformIntegerHyperparameter(name='FC_in_Conv__NumberBlocks', lower=1, upper=5, default_value=1,  log=False) ## DELETE, \n",
    "        #FC_in_Conv__NumberLayers = UniformIntegerHyperparameter(name='FC_in_Conv__NumberLayers', lower=1, upper=5, default_value=1,  log=False) ### DELETE\n",
    "        FC_in_Conv__dropout = UniformFloatHyperparameter(name='FC_in_Conv__dropout', lower=0.001, upper=0.4, default_value=0.02, log=True)\n",
    "        \n",
    "        # Other hyperparameters\n",
    "        lr = UniformFloatHyperparameter(name='lr', lower=1e-5, upper=1e-2, default_value=1e-4, log=True)\n",
    "        #LeakyReLU_alpha = UniformFloatHyperparameter(name='LeakyReLU_alpha', lower=0.01, upper=0.3, default_value=0.01, log=True) ## RELU\n",
    "        #kernel_initializer_list = CategoricalHyperparameter(name='kernel_initializer_list', choices=['he_normal', 'glorot_uniform']) ## CHECK\n",
    "\n",
    "        # Optimize size\n",
    "        # kernel_regularizer = Default\n",
    "        # MaxPooling1D: \n",
    "        # Gaus = keras.layers.GaussianNoise(0.01,)(input_1)\n",
    "   \n",
    "        \n",
    "        cs.add_hyperparameters([\n",
    "                                Conv__filters,\n",
    "                                Conv__kernel_size,\n",
    "                                Conv__MaxPooling1D,\n",
    "                                Conv__NumberLayers,\n",
    "                                Conv__NumberBlocks,\n",
    "            \n",
    "                                FC__units,\n",
    "                                FC__units_temperature,\n",
    "                                FC__units_c_o_ratio,\n",
    "                                FC__units_gravity,\n",
    "                                FC__units_metallicity,\n",
    "                                FC__NumberLayers,\n",
    "                                FC__dropout,\n",
    "                                FC_out_dropout,\n",
    "            \n",
    "                                FC_in_Conv__units,\n",
    "                                FC_in_Conv__dropout,\n",
    "            \n",
    "                                lr,\n",
    "                               ]) \n",
    "        \n",
    "        \n",
    "        return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0dd48-6401-4e7b-aada-657307ea8255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# Define the model architecture\n",
    "input_1 = tf.keras.layers.Input(shape=(104, 1))\n",
    "input_2 = tf.keras.layers.Input(shape=(2,))\n",
    "\n",
    "model  = Conv1D(64*2, 3, \n",
    "                 kernel_initializer = 'he_normal', \n",
    "                 activation='relu', \n",
    "                 input_shape=(104, 1))(input_1)\n",
    "\n",
    "model  = Conv1D(64*4, 3, \n",
    "                kernel_initializer = 'he_normal', \n",
    "                activation='relu')(model)\n",
    "\n",
    "model  = Conv1D(128*8, 3, \n",
    "                kernel_initializer = 'he_normal', \n",
    "                activation='relu')(model)\n",
    "\n",
    "model  = MaxPooling1D(2)(model)\n",
    "\n",
    "model  = Conv1D(128*8, 3, \n",
    "                kernel_initializer = 'he_normal', \n",
    "                activation='relu')(model)\n",
    "\n",
    "model  = Conv1D(128*16, 3, \n",
    "                kernel_initializer = 'he_normal', \n",
    "                activation='relu')(model)\n",
    "\n",
    "\n",
    "model  = MaxPooling1D(2)(model)\n",
    "model  = Flatten()(model)\n",
    "\n",
    "model = tf.keras.layers.concatenate([model, input_2], \n",
    "                                                   name='Concatenated_Layer')\n",
    "\n",
    "\n",
    "model  = Dense(128,                      \n",
    "                kernel_initializer = 'he_normal',\n",
    "                activation='relu')(model)\n",
    "\n",
    "model  = Dense(128*4,                      \n",
    "                kernel_initializer = 'he_normal',\n",
    "                activation='relu')(model)\n",
    "\n",
    "out__gravity =  Dense(1, \n",
    "                      activation='linear',\n",
    "                name='gravity')(model)  # No activation function for regression\n",
    "\n",
    "out__c_o_ratio = Dense(1, \n",
    "                      activation='linear',\n",
    "                      name='c_o_ratio')(model)  # No activation function for regression\n",
    "\n",
    "out__metallicity = Dense(1, \n",
    "                        activation='linear',\n",
    "                        name='metallicity')(model)  # No activation function for regression\n",
    "\n",
    "out__temperature = Dense(1, \n",
    "                        activation='linear',\n",
    "                        name='temperature')(model)  # No activation function for regression\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_1, input_2], \n",
    "                               outputs=[out__gravity, out__c_o_ratio, out__metallicity, out__temperature])\n",
    "\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and metrics\n",
    "model.compile(loss='huber_loss', \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.0001),  \n",
    "              metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x = [train_cnn_regression.X_train_normalized_rowwise, \n",
    "                         train_cnn_regression.X_train_standardized_columnwise], \n",
    "          y = [train_cnn_regression.y_train_standardized_columnwise[:,0], \n",
    "               train_cnn_regression.y_train_standardized_columnwise[:,1],\n",
    "               train_cnn_regression.y_train_standardized_columnwise[:,2],\n",
    "               train_cnn_regression.y_train_standardized_columnwise[:,3]], \n",
    "          batch_size = 32, \n",
    "          epochs = 30, \n",
    "          validation_data=([train_cnn_regression.X_val_normalized_rowwise, \n",
    "                            train_cnn_regression.X_val_standardized_columnwise], \n",
    "                          [train_cnn_regression.y_val_standardized_columnwise[:,0], \n",
    "                           train_cnn_regression.y_val_standardized_columnwise[:,1],\n",
    "                           train_cnn_regression.y_val_standardized_columnwise[:,2],\n",
    "                           train_cnn_regression.y_val_standardized_columnwise[:,3]]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bohb] *",
   "language": "python",
   "name": "conda-env-bohb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
